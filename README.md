Document Chat

This project is the Module1 publication for Ready Tensor Agentic AI Developer Certification 2025: AAIDC2025 

A powerful document management and conversation system that enables users to upload PDFs, process them with advanced AI embeddings, and have intelligent conversations with their documents using Google's Gemini AI.

ğŸš€ Features
    â€¢ PDF Document Upload: Drag-and-drop or browse to upload PDF documents 
    â€¢ Intelligent Document Processing: Automatic text extraction and chunking with overlap for better context retention 
    â€¢ Vector Search: FAISS-powered vector similarity search for relevant document retrieval 
    â€¢ AI-Powered Chat: Conversational interface using Google Gemini 1.5 Flash for natural language interactions 
    â€¢ Persistent Storage: Documents and metadata are stored locally for future sessions 
    â€¢ Real-time Processing: Live feedback during document upload and processing 
    â€¢ Modern UI: Clean, intuitive Gradio interface with drag-and-drop functionality 
ğŸ—ï¸ Architecture
The application follows a modular architecture with clear separation of concerns:
    â€¢ Document Processing Pipeline: Handles PDF text extraction and intelligent chunking 
    â€¢ Vector Store Management: FAISS-based embedding storage and retrieval 
    â€¢ Conversation Management: Google Gemini integration for AI responses 
    â€¢ Database Management: JSONL-based document metadata storage 
    â€¢ Web Interface: Gradio-powered responsive web UI 
ğŸ“ Project Structure
Progetto Eng/
â”œâ”€â”€ main.py                    # Application entry point with server management
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ .env                      # Environment variables (Google API key)
â”œâ”€â”€ rag/                      # RAG system modules
â”‚   â”œâ”€â”€ document_crud.py      # Document metadata management
â”‚   â”œâ”€â”€ embedding.py          # Google Gemini embedding integration
â”‚   â”œâ”€â”€ faiss_store.py        # FAISS vector database operations
â”‚   â”œâ”€â”€ pdf_loader.py         # PDF processing and chunking
â”‚   â””â”€â”€ retriever.py          # Document retrieval and AI response generation
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ gradio_app.py         # Gradio web interface
â””â”€â”€ data/                     # Document storage and metadata
    â”œâ”€â”€ documents.jsonl       # Document metadata database
    â”œâ”€â”€ faiss.index          # FAISS vector index
    â””â”€â”€ metadata.jsonl       # Vector metadata
ğŸ› ï¸ Dependencies
The project uses the following Python modules:
python-dotenv              # Environment variable management
google-generativeai        # Google Gemini AI integration
faiss-cpu                  # Vector similarity search
gradio                     # Web interface framework
numpy                      # Numerical computing
pandas                     # Data manipulation
pymupdf                    # PDF text extraction
sentence-transformers      # Alternative embedding models (optional)
ğŸ”§ Installation
    1. Clone the repository: 
git clone <repository-url>
cd gemini-document-chat
    2. Create a virtual environment: 
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
    3. Install dependencies: 
pip install -r requirements.txt
    4. Configure environment variables: Create a .env file in the project root and add your Google API key: 
GEMINI_API_KEY=your_google_gemini_api_key_here
Important: You need a valid Google Gemini API key. Get one from Google AI Studio
ğŸš€ Usage
    1. Start the application: 
python main.py
Optional parameters:
    â€¢ --port: Specify custom port (default: 7860) 
    â€¢ --no-browser: Don't open browser automatically 
    2. Access the interface: Open your browser and navigate to http://localhost:7860
    3. Upload and chat with documents:
        â—¦ Drag and drop PDF files into the upload area 
        â—¦ Click "Upload PDF" to process the document 
        â—¦ Use the chat interface to ask questions about your documents 
        â—¦ View document status in the sidebar 
ğŸ’¡ How It Works
    1. Document Upload: PDFs are uploaded and stored in the data/ directory 
    2. Text Extraction: PyMuPDF extracts text content from PDF files 
    3. Chunking: Documents are split into overlapping chunks (800 chars with 100 char overlap) 
    4. Embedding: Google Gemini's embedding model converts chunks to vector representations 
    5. Storage: Vectors are stored in FAISS index with metadata in JSONL format 
    6. Retrieval: User queries are embedded and matched against document vectors 
    7. Generation: Relevant chunks are sent to Gemini 1.5 Flash for contextual responses 
ğŸ” Technical Details
    â€¢ Embedding Model: Google's models/embedding-001 for document vectorization 
    â€¢ LLM: Gemini 1.5 Flash for conversational responses 
    â€¢ Vector Database: FAISS with Inner Product similarity search 
    â€¢ Document Format: Currently supports PDF files 
    â€¢ Chunking Strategy: Fixed-size chunks with overlap for context preservation 
    â€¢ Storage: Local filesystem with JSONL metadata format 
ğŸš¨ Requirements
    â€¢ Python 3.8+ 
    â€¢ Google Gemini API access 
    â€¢ Sufficient disk space for document storage 
    â€¢ Internet connection for AI model access 
âš ï¸ Limitations
    â€¢ Currently supports PDF documents only 
    â€¢ Requires internet connection for AI features 
    â€¢ Google API rate limits may apply 
    â€¢ Vector index is rebuilt on each startup (no persistent FAISS index loading optimization yet) 
ğŸ¤ Contributing
Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.
ğŸ“„ License
This project is open source and available under the MIT License.
ğŸ”— Related Projects
This project draws inspiration from modern RAG architectures and document management systems. It demonstrates practical implementation of:
    â€¢ Google Gemini AI integration 
    â€¢ FAISS vector search 
    â€¢ Gradio web interfaces 
    â€¢ Modular Python architecture 

Note: Make sure to keep your Google API key secure and never commit it to version control. Use the .env file as specified in the setup instructions.
